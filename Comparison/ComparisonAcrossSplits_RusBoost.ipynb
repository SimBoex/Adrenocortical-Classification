{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outer Fold</th>\n",
       "      <th>Grid-Search</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Auc-Score</th>\n",
       "      <th>#Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.801518</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.962</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800963</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.978</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.798512</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.966</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.808185</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.963</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.963</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.966</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.007</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outer Fold  Grid-Search  F1-score  Recall  Precision  Accuracy  Auc-Score  \\\n",
       "0         0.0     0.801518     0.792   0.905      0.704     0.905      0.962   \n",
       "1         1.0     0.800963     0.788   0.951      0.672     0.900      0.978   \n",
       "2         2.0     0.798512     0.835   0.905      0.776     0.928      0.966   \n",
       "3         3.0     0.808185     0.727   0.857      0.632     0.871      0.963   \n",
       "4         4.0     0.797101     0.812   0.929      0.722     0.914      0.963   \n",
       "5         NaN     0.801000     0.791   0.909      0.701     0.904      0.966   \n",
       "6         NaN     0.004000     0.040   0.035      0.054     0.021      0.007   \n",
       "\n",
       "   #Features  \n",
       "0         66  \n",
       "1         60  \n",
       "2         74  \n",
       "3         67  \n",
       "4         67  \n",
       "5         67  \n",
       "6          4  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scores_boruta = pd.read_csv('../Elements/Boruta_RusBoost/AcrossSplits/scores.csv')\n",
    "scores_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outer Fold</th>\n",
       "      <th>Grid-Search</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Auc-Score</th>\n",
       "      <th>#Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789845</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.963</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811912</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.974</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802535</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.976</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.808185</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.961</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.787072</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.964</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.968</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outer Fold  Grid-Search  F1-score  Recall  Precision  Accuracy  Auc-Score  \\\n",
       "0         0.0     0.789845     0.771   0.881      0.685     0.895      0.963   \n",
       "1         1.0     0.811912     0.804   0.951      0.696     0.909      0.974   \n",
       "2         2.0     0.802535     0.831   0.881      0.787     0.928      0.976   \n",
       "3         3.0     0.808185     0.720   0.857      0.621     0.866      0.961   \n",
       "4         4.0     0.787072     0.792   0.952      0.678     0.900      0.964   \n",
       "5         NaN     0.800000     0.784   0.904      0.693     0.900      0.968   \n",
       "6         NaN     0.011000     0.042   0.044      0.060     0.023      0.007   \n",
       "\n",
       "   #Features  \n",
       "0        124  \n",
       "1        124  \n",
       "2        124  \n",
       "3        124  \n",
       "4        124  \n",
       "5        124  \n",
       "6          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scores_rus = pd.read_csv('../Elements/RusBoost/AcrossSplits/scores.csv')\n",
    "scores_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.792\n",
       "1    0.788\n",
       "2    0.835\n",
       "3    0.727\n",
       "4    0.812\n",
       "Name: F1-score, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_boruta = scores_boruta[\"F1-score\"][:-2]\n",
    "f1_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon test: w-statistic = 3.0000, p-value = 0.3125\n",
      "Fail to reject the null hypothesis (no significant difference between the two models).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, wilcoxon, ttest_ind, mannwhitneyu\n",
    "\n",
    "# Replace these with your actual data values\n",
    "f1_boruta = scores_boruta[\"F1-score\"][:-2]\n",
    "f1_rus = scores_rus[\"F1-score\"][:-2]\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (if samples are related) or Mann-Whitney U test (if independent)\n",
    "w_stat, p_value_wilcoxon = wilcoxon(f1_boruta, f1_rus)  # Use mannwhitneyu for independent samples\n",
    "\n",
    "\n",
    "# Output the Wilcoxon test results and decision\n",
    "print(\"Wilcoxon test: w-statistic = {:.4f}, p-value = {:.4f}\".format(w_stat, p_value_wilcoxon))\n",
    "if p_value_wilcoxon < alpha:\n",
    "    print(\"Reject the null hypothesis (significant difference between the two models).\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis (no significant difference between the two models).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon test: w-statistic = 1.0000, p-value = 0.2763\n",
      "Fail to reject the null hypothesis (no significant difference between the two models).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/PredictiveModelsAdrenoTumors/lib/python3.10/site-packages/scipy/stats/_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/simone/anaconda3/envs/PredictiveModelsAdrenoTumors/lib/python3.10/site-packages/scipy/stats/_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, wilcoxon, ttest_ind, mannwhitneyu\n",
    "\n",
    "# Replace these with your actual data values\n",
    "Recall_boruta = scores_boruta[\"Recall\"][:-2]\n",
    "Recall_rus = scores_rus[\"Recall\"][:-2]\n",
    "# Perform Wilcoxon signed-rank test (if samples are related) or Mann-Whitney U test (if independent)\n",
    "w_stat, p_value_wilcoxon = wilcoxon(Recall_boruta, Recall_rus)  \n",
    "\n",
    "\n",
    "# Output the Wilcoxon test results and decision\n",
    "print(\"Wilcoxon test: w-statistic = {:.4f}, p-value = {:.4f}\".format(w_stat, p_value_wilcoxon))\n",
    "if p_value_wilcoxon < alpha:\n",
    "    print(\"Reject the null hypothesis (significant difference between the two models).\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis (no significant difference between the two models).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon test: w-statistic = 5.5000, p-value = 0.8125\n",
      "Fail to reject the null hypothesis (no significant difference between the two models).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, wilcoxon, ttest_ind, mannwhitneyu\n",
    "\n",
    "# Replace these with your actual data values\n",
    "Precision_boruta = scores_boruta[\"Precision\"][:-2]\n",
    "Precision_rus = scores_rus[\"Precision\"][:-2]\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (if samples are related) or Mann-Whitney U test (if independent)\n",
    "w_stat, p_value_wilcoxon = wilcoxon(Precision_boruta, Precision_rus)  # Use mannwhitneyu for independent samples\n",
    "\n",
    "\n",
    "# Output the Wilcoxon test results and decision\n",
    "print(\"Wilcoxon test: w-statistic = {:.4f}, p-value = {:.4f}\".format(w_stat, p_value_wilcoxon))\n",
    "if p_value_wilcoxon < alpha:\n",
    "    print(\"Reject the null hypothesis (significant difference between the two models).\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis (no significant difference between the two models).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PredictiveModelsAdrenoTumors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
